{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b23c29d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Store_id</th>\n",
       "      <th>Store_Type</th>\n",
       "      <th>Location_Type</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Discount</th>\n",
       "      <th>#Order</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1000001</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>L3</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "      <td>7011.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1000002</td>\n",
       "      <td>253</td>\n",
       "      <td>S4</td>\n",
       "      <td>L2</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>60</td>\n",
       "      <td>51789.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T1000003</td>\n",
       "      <td>252</td>\n",
       "      <td>S3</td>\n",
       "      <td>L2</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>42</td>\n",
       "      <td>36868.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T1000004</td>\n",
       "      <td>251</td>\n",
       "      <td>S2</td>\n",
       "      <td>L3</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>23</td>\n",
       "      <td>19715.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T1000005</td>\n",
       "      <td>250</td>\n",
       "      <td>S2</td>\n",
       "      <td>L3</td>\n",
       "      <td>R4</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>62</td>\n",
       "      <td>45614.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Store_id Store_Type Location_Type Region_Code        Date  \\\n",
       "0  T1000001         1         S1            L3          R1  2018-01-01   \n",
       "1  T1000002       253         S4            L2          R1  2018-01-01   \n",
       "2  T1000003       252         S3            L2          R1  2018-01-01   \n",
       "3  T1000004       251         S2            L3          R1  2018-01-01   \n",
       "4  T1000005       250         S2            L3          R4  2018-01-01   \n",
       "\n",
       "   Holiday Discount  #Order     Sales  \n",
       "0        1      Yes       9   7011.84  \n",
       "1        1      Yes      60  51789.12  \n",
       "2        1      Yes      42  36868.20  \n",
       "3        1      Yes      23  19715.16  \n",
       "4        1      Yes      62  45614.52  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = r'C:\\Users\\girip\\Downloads\\TRAIN.csv'   # <- put your real path here\n",
    "dataset = pd.read_csv(file)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff35550a",
   "metadata": {},
   "source": [
    "##Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54963bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure Date is datetime, sort by Store_id & Date, then create features and rolling mean\n",
    "dataset['Date'] = pd.to_datetime(dataset['Date'])\n",
    "dataset = dataset.sort_values(['Store_id', 'Date']).reset_index(drop=True)\n",
    "\n",
    "dataset['Year'] = dataset['Date'].dt.year\n",
    "dataset['Month'] = dataset['Date'].dt.month\n",
    "dataset['DayOfWeek'] = dataset['Date'].dt.dayofweek\n",
    "\n",
    "dataset['Sales_Rolling_Mean_7D'] = dataset.groupby('Store_id')['Sales'] \\\n",
    "    .transform(lambda x: x.rolling(window=7, min_periods=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc836af",
   "metadata": {},
   "source": [
    "#Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6a18193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features scaled successfully.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identify numerical features to be scaled\n",
    "numerical_features = ['#Order', 'Sales', 'Sales_Rolling_Mean_7D']\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler to the selected numerical features and update the dataset\n",
    "dataset[numerical_features] = scaler.fit_transform(dataset[numerical_features])\n",
    "\n",
    "print(\"Numerical features scaled successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ef15753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features one-hot encoded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Identify categorical features to be one-hot encoded\n",
    "categorical_features = ['Store_Type', 'Location_Type', 'Region_Code', 'Discount']\n",
    "\n",
    "# Apply one-hot encoding\n",
    "dataset = pd.get_dummies(dataset, columns=categorical_features, drop_first=True)\n",
    "\n",
    "print(\"Categorical features one-hot encoded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a1ca2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataset.drop(['Sales', 'ID', 'Date'], axis=1)\n",
    "y_train = dataset['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7db06a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression model re-trained on the entire X_train and y_train datasets.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "final_model_lr = LinearRegression()\n",
    "final_model_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Linear Regression model re-trained on the entire X_train and y_train datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d4388e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression model saved to 'linear_regression_model.joblib'.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained Linear Regression model to a file\n",
    "joblib.dump(final_model_lr, 'linear_regression_model.joblib')\n",
    "\n",
    "print(\"Linear Regression model saved to 'linear_regression_model.joblib'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a22fbd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler saved to 'scaler.joblib'.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the fitted StandardScaler instance to a file\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "print(\"StandardScaler saved to 'scaler.joblib'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "942e754c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified and saved list of one-hot encoded columns to 'encoded_columns.joblib'.\n",
      "Number of encoded columns: 13\n",
      "First 5 encoded columns: ['#Order', 'Sales_Rolling_Mean_7D', 'Store_Type_S2', 'Store_Type_S3', 'Store_Type_S4']\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Define the non-one-hot encoded columns (numerical + Holiday)\n",
    "non_encoded_cols = ['Store_id', 'Year', 'Month', 'DayOfWeek', 'Holiday']\n",
    "\n",
    "# Identify the one-hot encoded columns by excluding the non_encoded_cols from X_train's columns\n",
    "encoded_columns = [col for col in X_train.columns if col not in non_encoded_cols]\n",
    "\n",
    "# Save the list of encoded column names\n",
    "joblib.dump(encoded_columns, 'encoded_columns.joblib')\n",
    "\n",
    "print(\"Identified and saved list of one-hot encoded columns to 'encoded_columns.joblib'.\")\n",
    "print(f\"Number of encoded columns: {len(encoded_columns)}\")\n",
    "print(\"First 5 encoded columns:\", encoded_columns[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa9b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the pre-trained model, scaler, and encoded columns\n",
    "final_model_lr = joblib.load('linear_regression_model.joblib')\n",
    "scaler = joblib.load('scaler.joblib')\n",
    "encoded_columns = joblib.load('encoded_columns.joblib')\n",
    "\n",
    "# Define the non-encoded numerical columns that need scaling\n",
    "numerical_features_for_scaling = ['Store_id', 'Year', 'Month', 'DayOfWeek']\n",
    "\n",
    "# Define the categorical columns that were one-hot encoded\n",
    "categorical_features_for_encoding = ['Store_Type', 'Location_Type', 'Region_Code', 'Discount']\n",
    "\n",
    "# 2. Define the preprocessing function\n",
    "def preprocess_input(data):\n",
    "    # Convert the input dictionary to a pandas DataFrame\n",
    "    input_df = pd.DataFrame([data])\n",
    "\n",
    "    # Convert 'Date' column to datetime objects\n",
    "    input_df['Date'] = pd.to_datetime(input_df['Date'])\n",
    "\n",
    "    # Extract 'Year', 'Month', and 'DayOfWeek' features\n",
    "    input_df['Year'] = input_df['Date'].dt.year\n",
    "    input_df['Month'] = input_df['Date'].dt.month\n",
    "    input_df['DayOfWeek'] = input_df['Date'].dt.dayofweek\n",
    "\n",
    "    # Drop the original 'Date' column as it's no longer needed\n",
    "    input_df = input_df.drop('Date', axis=1)\n",
    "\n",
    "    # Apply one-hot encoding to categorical features\n",
    "    input_df_encoded = pd.get_dummies(input_df, columns=categorical_features_for_encoding, drop_first=True)\n",
    "\n",
    "    # Align columns with the training data's encoded columns\n",
    "    # First, identify all columns that should be present in the final DataFrame\n",
    "    expected_columns = numerical_features_for_scaling + ['Holiday'] + encoded_columns\n",
    "    \n",
    "    # Reindex the input_df_encoded to match the expected columns. Fill missing with 0 and remove extra.\n",
    "    input_df_final = input_df_encoded.reindex(columns=expected_columns, fill_value=0)\n",
    "\n",
    "    # Scale the numerical features\n",
    "    input_df_final[numerical_features_for_scaling] = scaler.transform(input_df_final[numerical_features_for_scaling])\n",
    "\n",
    "    return input_df_final\n",
    "\n",
    "# 3. Initialize the Flask application\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 4. Create a prediction endpoint\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.get_json(force=True)\n",
    "        preprocessed_data = preprocess_input(data)\n",
    "        prediction = final_model_lr.predict(preprocessed_data)\n",
    "        return jsonify({'predicted_sales': prediction[0].item()})\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 400\n",
    "\n",
    "# To run the Flask app, you would typically save this code as app.py and run `flask run`\n",
    "# For demonstration purposes, we can include a main block here, but it's not ideal for production.\n",
    "if __name__ == '__main__':\n",
    "    print(\"Flask app loaded. You can run this file to start the development server.\")\n",
    "    print(\"Example usage (if running locally): curl -X POST -H \\\"Content-Type: application/json\\\" -d '{\\\"Store_id\\\": 1, \\\"Store_Type\\\": \\\"S1\\\", \\\"Location_Type\\\": \\\"L1\\\", \\\"Region_Code\\\": \\\"R1\\\", \\\"Date\\\": \\\"2019-06-01\\\", \\\"Holiday\\\": 0, \\\"Discount\\\": \\\"No\\\"}' http://127.0.0.1:5000/predict\")\n",
    "    # app.run(debug=True) # Uncomment to run the app, debug=True for development"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
